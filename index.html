<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>三多之路 - From Zero To One Hundred</title><meta name="author" content="侯三多"><meta name="copyright" content="侯三多"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="追求极致之美">
<meta property="og:type" content="website">
<meta property="og:title" content="三多之路">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="三多之路">
<meta property="og:description" content="追求极致之美">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/img/avatar.jpg">
<meta property="article:author" content="侯三多">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/avatar.jpg"><link rel="shortcut icon" href="/img/avatar.jpg"><link rel="canonical" href="http://example.com/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><script>var GLOBAL_CONFIG = { 
  root: '/',
  hexoversion: '5.2.0',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: 'days',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: {"limitCount":100,"languages":{"author":"Author: 侯三多","link":"Link: ","source":"Source: 三多之路","info":"Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source."}},
  ClickShowText: {"text":"I,LOVE,YOU","fontSize":"15px"},
  lightbox: 'fancybox',
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isSidebar: false,
  postUpdate: '2020-12-06 16:17:22'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {
  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }

  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }
})()</script><meta name="generator" content="Hexo 5.2.0"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">18</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/talk/"><i class="fa-fw Fas Fa-Cloud-Sun"></i><span> Comments</span></a></div></div></div></div><div id="body-wrap"><header class="full_page" id="page-header" style="background-image: url(/img/background3.JPG)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">三多之路</a></span><span id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/talk/"><i class="fa-fw Fas Fa-Cloud-Sun"></i><span> Comments</span></a></div></div><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="site-info"><h1 id="site-title">三多之路</h1><div id="site-subtitle"><span id="subtitle"></span></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout_page" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/10/28/DL-%E3%80%8A%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%8B%E7%AC%94%E8%AE%B0/" title="《动手学深度学习》笔记">     <img class="post_bg" src="https://store-images.s-microsoft.com/image/apps.26922.14224260644356105.8c88ca90-ccbc-4f4e-b92b-a1ca170cbc77.793aac39-a892-4f68-88ca-95533c261ebd?mode=scale&amp;q=90&amp;h=1080&amp;w=1920" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="《动手学深度学习》笔记"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/10/28/DL-%E3%80%8A%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%8B%E7%AC%94%E8%AE%B0/" title="《动手学深度学习》笔记">《动手学深度学习》笔记</a><div class="article-meta-wrap"><span class="article-meta"><i class="fas fa-thumbtack article-meta__icon sticky"></i><span class="sticky">Sticky</span><span class="article-meta__separator">|</span></span><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-10-28T10:10:44.000Z" title="Created 2020-10-28 18:10:44">2020-10-28</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/Deep-Learning/">Deep Learning</a></span></div><div class="content">相关资料：书籍地址
maxnet官网
Chapter2：预备知识获取和运行本书的代码环境配置按照官网教程即可实现，可能会遇到一个问题，我的cuda是10.0版本，在修改environment文件时要写成mxnet100，这样就可以运行了。
另外我是在GPU服务器上运行，为了可以在自己的浏览器打开jupyternotebook，需要设置一下，具体设置自行百度，唯一需要注意的是，修改文件后一定要把修改配置前的“#”删去，否则是无效的。
Chapter3：深度学习基础线性回归当模型和损失函数形式较为简单时，其误差最小化问题的解可以直接用公式表达出来。这类解叫作解析解（analytical solution）。
大多数深度学习模型并没有解析解，只能通过优化算法有限次迭代模型参数来尽可能降低损失函数的值。这类解叫作数值解（numerical solution）
对于求解数值解，小批量随机梯度下降（mini-batch stochastic gradient descent）在深度学习中被广泛使用，其做法就是选定一个初始点w0，然后w0沿着梯度下降到方向移动一定的距离，知道找到最小点。
线性回归模 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/10/15/ML-%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E6%9D%8E%E5%AE%8F%E6%AF%85%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" title="《机器学习（李宏毅2020spring）》学习笔记(持续更新)">     <img class="post_bg" src="https://store-images.s-microsoft.com/image/apps.30419.14224260644356105.8c88ca90-ccbc-4f4e-b92b-a1ca170cbc77.4b0fd7af-3555-4a2d-adc6-a91cf51f30bb?w=672&amp;h=378&amp;q=80&amp;mode=letterbox&amp;background=%23FFE4E4E4&amp;format=jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="《机器学习（李宏毅2020spring）》学习笔记(持续更新)"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/10/15/ML-%E3%80%8A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E6%9D%8E%E5%AE%8F%E6%AF%85%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" title="《机器学习（李宏毅2020spring）》学习笔记(持续更新)">《机器学习（李宏毅2020spring）》学习笔记(持续更新)</a><div class="article-meta-wrap"><span class="article-meta"><i class="fas fa-thumbtack article-meta__icon sticky"></i><span class="sticky">Sticky</span><span class="article-meta__separator">|</span></span><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-10-15T11:18:35.000Z" title="Created 2020-10-15 19:18:35">2020-10-15</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/Machine-Learning/">Machine Learning</a></span></div><div class="content">相关资料李宏毅老师：个人主页在这里有上课的课件、课后题目数据集及源码
课程视频（B站）：B站
课程笔记：GitHub1、GitHub2
作业说明及范例：GitHub
动手学深度学习：这本书也不错，理论与实践结合紧密
深度学习路线图
Neural Networks and Deep Learning
CNN十大经典论文
TensorFlow：http://c.biancheng.net/view/1911.html
这个也可以参考一下：https://blog.csdn.net/iteapoy/article/details/105382315
Learning Map



HomeWork


序号
任务
完成情况
完成时间



1
Linear Regression
✔Regression
2020/10/19


2
Classification
✔Classification
2020/10/21


3
CNN
待完成



P4 Basic ConceptBias and Variance如何区分理解？
偏差(Bias)和方差(Variance)——机器学习中的模型选择
 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/11/18/%E8%AE%BA%E6%96%87-DeepLearning%E7%BB%BC%E8%BF%B0/" title="论文-深度学习综述">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="论文-深度学习综述"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/11/18/%E8%AE%BA%E6%96%87-DeepLearning%E7%BB%BC%E8%BF%B0/" title="论文-深度学习综述">论文-深度学习综述</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-11-18T06:12:33.000Z" title="Created 2020-11-18 14:12:33">2020-11-18</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/Deep-Learning/">Deep Learning</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/Paper-Recurrence/">Paper Recurrence</a></span></div><div class="content">
LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton. “Deep learning.” Nature 521.7553 (2015): 436-444. [pdf] (Three Giants’ Survey) 

深度学习允许由多个处理层组成的计算模型学习具有多个抽象层次的数据表示。这些方法极大地提高了语音识别、视觉对象识别、对象检测和许多其他领域(如药物发现和基因组学)的技术水平。深度学习通过使用反向传播算法指示机器应该如何改变其内部参数来发现大型数据集中复杂的结构，该内部参数用于从前一层的表示计算每一层的表示。深度卷积网络在处理图像、视频、语音和音频方面带来了突破，而循环网络则照亮了文本和语音等连续数据。
The difference between Machie learning and Deep Learning传统的机器学习技术在处理原始形式的自然数据方面能力有限。几十年来，构建模式识别或机器学习系统需要仔细的工程设计和大量的领域专业知识来设计特征提取器；
表示学习是一套方法，它允许机器获得原始数据，并自动发现检测或分类所需的表 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/11/16/DL-RNN%E6%97%B6%E5%BA%8F%E6%95%B0%E6%8D%AE%E7%9A%84%E9%87%87%E6%A0%B7/" title="RNN——时序数据的采样">     <img class="post_bg" src="https://store-images.s-microsoft.com/image/apps.2228.14212623725120134.623fdbc1-19d2-4782-9ec0-3689031a5351.e7b5cc29-6372-4da7-8d63-b6a64e346d99?mode=scale&amp;q=90&amp;h=1080&amp;w=1920" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="RNN——时序数据的采样"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/11/16/DL-RNN%E6%97%B6%E5%BA%8F%E6%95%B0%E6%8D%AE%E7%9A%84%E9%87%87%E6%A0%B7/" title="RNN——时序数据的采样">RNN——时序数据的采样</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-11-16T02:38:31.000Z" title="Created 2020-11-16 10:38:31">2020-11-16</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/Deep-Learning/">Deep Learning</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/RNN/">RNN</a></span></div><div class="content">语言模型数据集读取数据集12345678from mxnet import ndimport randomimport zipfilewith zipfile.ZipFile(&#x27;../data/jaychou_lyrics.txt.zip&#x27;) as zin:    with zin.open(&#x27;jaychou_lyrics.txt&#x27;) as f:        corpus_chars = f.read().decode(&#x27;utf-8&#x27;)corpus_chars[:40]




&#39;想要有直升机\n想要和你飞到宇宙去\n想要和你融化在一起\n融化在宇宙里\n我每天每天每&#39;
123corpus_chars = corpus_chars.replace(&#x27;\n&#x27;, &#x27; &#x27;).replace(&#x27;\t&#x27;, &#x27; &#x27;)corpus_chars = corpus_chars[0:10000]corpus_chars[0:49]




&#39; ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/11/12/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94-NiN%E6%A8%A1%E5%9E%8B/" title="CNN经典论文—-NiN模型">     <img class="post_bg" src="https://store-images.s-microsoft.com/image/apps.6912.14452294709695665.572e989b-8bfc-4241-ad95-9639e428f0b4.f17657f3-08e4-4812-a70c-c48f329a578e?mode=scale&amp;q=90&amp;h=1080&amp;w=1920A" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CNN经典论文—-NiN模型"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/11/12/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94-NiN%E6%A8%A1%E5%9E%8B/" title="CNN经典论文—-NiN模型">CNN经典论文—-NiN模型</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-11-12T08:40:31.000Z" title="Created 2020-11-12 16:40:31">2020-11-12</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/Deep-Learning/">Deep Learning</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/Paper-Recurrence/">Paper Recurrence</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/CNN/">CNN</a></span></div><div class="content">NiNe同AlexNet和VGG网络的区别

1x1卷积层卷积窗口形状为1×1（kh=kw=1）的多通道卷积层。我们通常称之为1×1卷积层，并将其中的卷积运算称为1×1卷积。因为使用了最小窗口，1×1卷积失去了卷积层可以识别高和宽维度上相邻元素构成的模式的功能，其主要计算发生在通道维上。下图展示了使用输入通道数为3、输出通道数为2的1×1卷积核的互相关计算。值得注意的是，输入和输出具有相同的高和宽。输出中的每个元素来自输入中在高和宽上相同位置的元素在不同通道之间的按权重累加。假设我们将通道维当作特征维，将高和宽维度上的元素当成数据样本那么1×1卷积层的作用与全连接层等价。


网络结构
传统的convolution层
传统的卷积层，通过卷积核得到


单通道mlpconv层


跨通道的mlpconv






</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/11/10/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94%E2%80%94VGG%E6%A8%A1%E5%9E%8B/" title="CNN经典算法——VGG模型">     <img class="post_bg" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CNN经典算法——VGG模型"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/11/10/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94%E2%80%94VGG%E6%A8%A1%E5%9E%8B/" title="CNN经典算法——VGG模型">CNN经典算法——VGG模型</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-11-10T12:02:31.000Z" title="Created 2020-11-10 20:02:31">2020-11-10</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/Deep-Learning/">Deep Learning</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/Paper-Recurrence/">Paper Recurrence</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/CNN/">CNN</a></span></div><div class="content">VGG原理

VGG有两种结构，分别是VGG16（上图D列）和VGG19（上图E列)，两者并没有本质上的区别，只是网络深度不一样。
VGG16相比AlexNet的一个改进是采用连续的几个3x3的卷积核代替AlexNet中的较大卷积核（11x11，7x7，5x5）。VGGNet的结构非常简洁，整个网络都使用了同样大小的卷积核尺寸（3x3）和最大池化尺寸（2x2）。
两个3x3的卷积层串联相当于1个5x5的卷积层，即一个像素会跟周围5x5的像素产生关联，可以说感受野大小为5x5。而3个3x3的卷积层串联的效果则相当于1个7x7的卷积层;
参数：
https://zhuanlan.zhihu.com/p/41423739
</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/11/10/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94%E2%80%94AlexNet%E6%A8%A1%E5%9E%8B/" title="CNN经典算法——AlexNet模型">     <img class="post_bg" src="https://store-images.s-microsoft.com/image/apps.14244.14388828775882433.23aa3542-3c16-4cce-a37c-033114a9ef30.d33d8ce6-a845-4912-9947-56e10f1ddf70?mode=scale&amp;q=90&amp;h=1080&amp;w=1920" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CNN经典算法——AlexNet模型"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/11/10/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94%E2%80%94AlexNet%E6%A8%A1%E5%9E%8B/" title="CNN经典算法——AlexNet模型">CNN经典算法——AlexNet模型</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-11-10T01:27:04.000Z" title="Created 2020-11-10 09:27:04">2020-11-10</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/Deep-Learning/">Deep Learning</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/Paper-Recurrence/">Paper Recurrence</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/CNN/">CNN</a></span></div><div class="content">2012年，AlexNet横空出世。这个模型的名字来源于论文第一作者的姓名Alex Krizhevsky [1]。AlexNet使用了8层卷积神经网络，并以很大的优势赢得了ImageNet 2012图像识别挑战赛。


第一，与相对较小的LeNet相比，AlexNet包含8层变换，其中有5层卷积和2层全连接隐藏层，以及1个全连接输出层。

AlexNet第一层中的卷积窗口形状是11×11，strides=4。因为ImageNet中绝大多数图像的高和宽均比MNIST图像的高和宽大10倍以上，ImageNet图像的物体占用更多的像素，所以需要更大的卷积窗口来捕获物体。
第二层中的卷积窗口形状减小到5×5；第三、四、五层的卷积窗口大小为3x3.
第一、第二和第五个卷积层之后都使用了窗口形状为3×3、步幅为2的最大池化层；而第三、四个卷积层之后没有池化层。

第二，AlexNet将sigmoid激活函数改成了更加简单的ReLU激活函数。

一方面，ReLU激活函数的计算更简单，例如它并没有sigmoid激活函数中的求幂运算。
另一方面，ReLU激活函数在不同的参数初始化方法下使模型更容易训练。 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/11/09/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94%E2%80%94LeNet%E6%A8%A1%E5%9E%8B%E5%A4%8D%E7%8E%B0/" title="CNN经典算法——LeNet模型">     <img class="post_bg" src="https://store-images.s-microsoft.com/image/apps.16984.13536745346176445.c1a01236-b41f-4666-a4c8-6470a9849dec.0901ee9b-e081-49af-823e-b690b5c32a71?mode=scale&amp;q=90&amp;h=1080&amp;w=1920" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CNN经典算法——LeNet模型"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/11/09/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94%E2%80%94LeNet%E6%A8%A1%E5%9E%8B%E5%A4%8D%E7%8E%B0/" title="CNN经典算法——LeNet模型">CNN经典算法——LeNet模型</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-11-09T02:59:46.000Z" title="Created 2020-11-09 10:59:46">2020-11-09</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/Deep-Learning/">Deep Learning</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/Paper-Recurrence/">Paper Recurrence</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/CNN/">CNN</a></span></div><div class="content">LeNet模型介绍

LeNet网络基本架构为：conv1 (6) -&gt; pool1 -&gt; conv2 (16) -&gt; pool2 -&gt; fc3 (120) -&gt; fc4 (84) -&gt; fc5 (10) -&gt; softmax，括号内数字表示channel数。
该网络包含五层，两个卷积（卷积层、池化层)，两个全连接层，一个输出层。
其中卷积层的卷积核大小为5x5，stride=1；池化层为最大池化层，卷积核大小为2x2，strides=2；全连接层的输出个数分别为120， 84， 10.
LeNet模型复现参考：《动手学深度学习》Chapter5
12345import d2lzh as d2limport mxnet as mxfrom mxnet import autograd, gluon, init, ndfrom mxnet.gluon import loss as gloss, nnimport time

基于Sequntial类构造模型经历一次卷积层，其高和宽为(h-k+1)*(w-k+1)；经历一次池化层，其宽和高减半；这个过 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/11/04/ML-my-hw3-cnn/" title="《机器学习（李宏毅2020spring）》作业3：CNN">     <img class="post_bg" src="https://store-images.s-microsoft.com/image/apps.11416.13666079135464041.262c63a4-3d2e-4fcb-862d-2038cfd9fdf3.50843114-bc48-4a75-9018-4a09fa8ccc4d?mode=scale&amp;q=90&amp;h=1080&amp;w=1920" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="《机器学习（李宏毅2020spring）》作业3：CNN"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/11/04/ML-my-hw3-cnn/" title="《机器学习（李宏毅2020spring）》作业3：CNN">《机器学习（李宏毅2020spring）》作业3：CNN</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-11-04T03:09:26.000Z" title="Created 2020-11-04 11:09:26">2020-11-04</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/Machine-Learning/">Machine Learning</a></span></div><div class="content">作业说明：CNN分类问题根据实物照片进行分类，照片的命名规则是“类别_编号.jpg”，类别也是用数字表示，共有11类，Bread, Dairy product, Dessert, Egg, Fried food, Meat, Noodles/Pasta, Rice, Seafood, Soup, and Vegetable/Fruit；其实具体类别是什么我们可以不用管，只需要训练的时候输入数据，输出类别即可。training 以及 validation 中的照片名名称格式為“类别_编号.jpg”，例如 3_100.jpg 即为类别 3 的照片（编号不重要）testing 中的照片名稱格式為 [编号].jpg数据集需要提前下载下来，解压即可，范例中是从谷歌云下载的，需要翻墙，比较麻烦参考：李宏毅机器学习第三次作业源码
导入需要的包cv2需要额外安装，直接输入命令pip install opencv-python即可完成
12345678910# Import需要的套件import osimport numpy as npimport cv2import torchimport torch ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/10/31/DL-softmax%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/" title="softmax回归模型">     <img class="post_bg" src="https://store-images.s-microsoft.com/image/apps.53636.14077318991609137.74bb1f9d-01ce-4ec6-aecf-81719875e023.05ba4878-0779-4c67-b36d-5fba9acee597?mode=scale&amp;q=90&amp;h=1080&amp;w=1920" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="softmax回归模型"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/10/31/DL-softmax%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/" title="softmax回归模型">softmax回归模型</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-10-31T06:38:20.000Z" title="Created 2020-10-31 14:38:20">2020-10-31</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/Machine-Learning/">Machine Learning</a><span class="article-meta__link">•</span><a class="article-meta__tags" href="/tags/Deep-Learning/">Deep Learning</a></span></div><div class="content">
线性回归输出结果为连续值，而对于分类问题，需要输出离散值，而softmax可以有效解决这一问题。

softmax回归从零开始实现1234%matplotlib inlineimport d2lzh as d2lfrom mxnet import autograd, nd

读取数据集12batch_size = 256train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)

初始化参数模型由于像素为28*28，因此输入为784，而输出为10个类别
123456789num_inputs = 784num_outputs = 10W = nd.random.normal(scale=0.01, shape=(num_inputs, num_outputs))b = nd.zeros(num_outputs)#梯度W.attach_grad()b.attach_grad()

softmax运算实现123#看一下三维矩阵的运算X = nd.array([[1, 2, 3], [4, 5, 6]])X.sum(axi ...</div></div></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside_content" id="aside_content"><div class="card-widget card-info"><div class="card-content"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">侯三多</div><div class="author-info__description">追求极致之美</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">18</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">7</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/HouSanDuo123"><i class="fab fa-github"></i><span>Follow Me</span></a></div></div><div class="sticky_layout"><div class="card-widget card-announcement"><div class="card-content"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">Welcome my Blog!</div></div></div><div class="card-widget card-recent-post"><div class="card-content"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2020/11/18/%E8%AE%BA%E6%96%87-DeepLearning%E7%BB%BC%E8%BF%B0/" title="论文-深度学习综述"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="论文-深度学习综述"/></a><div class="content"><a class="title" href="/2020/11/18/%E8%AE%BA%E6%96%87-DeepLearning%E7%BB%BC%E8%BF%B0/" title="论文-深度学习综述">论文-深度学习综述</a><time datetime="2020-11-18T06:12:33.000Z" title="Created 2020-11-18 14:12:33">2020-11-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/11/16/DL-RNN%E6%97%B6%E5%BA%8F%E6%95%B0%E6%8D%AE%E7%9A%84%E9%87%87%E6%A0%B7/" title="RNN——时序数据的采样"><img src="https://store-images.s-microsoft.com/image/apps.2228.14212623725120134.623fdbc1-19d2-4782-9ec0-3689031a5351.e7b5cc29-6372-4da7-8d63-b6a64e346d99?mode=scale&amp;q=90&amp;h=1080&amp;w=1920" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="RNN——时序数据的采样"/></a><div class="content"><a class="title" href="/2020/11/16/DL-RNN%E6%97%B6%E5%BA%8F%E6%95%B0%E6%8D%AE%E7%9A%84%E9%87%87%E6%A0%B7/" title="RNN——时序数据的采样">RNN——时序数据的采样</a><time datetime="2020-11-16T02:38:31.000Z" title="Created 2020-11-16 10:38:31">2020-11-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/11/12/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94-NiN%E6%A8%A1%E5%9E%8B/" title="CNN经典论文—-NiN模型"><img src="https://store-images.s-microsoft.com/image/apps.6912.14452294709695665.572e989b-8bfc-4241-ad95-9639e428f0b4.f17657f3-08e4-4812-a70c-c48f329a578e?mode=scale&amp;q=90&amp;h=1080&amp;w=1920A" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CNN经典论文—-NiN模型"/></a><div class="content"><a class="title" href="/2020/11/12/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94-NiN%E6%A8%A1%E5%9E%8B/" title="CNN经典论文—-NiN模型">CNN经典论文—-NiN模型</a><time datetime="2020-11-12T08:40:31.000Z" title="Created 2020-11-12 16:40:31">2020-11-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/11/10/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94%E2%80%94VGG%E6%A8%A1%E5%9E%8B/" title="CNN经典算法——VGG模型"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CNN经典算法——VGG模型"/></a><div class="content"><a class="title" href="/2020/11/10/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94%E2%80%94VGG%E6%A8%A1%E5%9E%8B/" title="CNN经典算法——VGG模型">CNN经典算法——VGG模型</a><time datetime="2020-11-10T12:02:31.000Z" title="Created 2020-11-10 20:02:31">2020-11-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2020/11/10/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94%E2%80%94AlexNet%E6%A8%A1%E5%9E%8B/" title="CNN经典算法——AlexNet模型"><img src="https://store-images.s-microsoft.com/image/apps.14244.14388828775882433.23aa3542-3c16-4cce-a37c-033114a9ef30.d33d8ce6-a845-4912-9947-56e10f1ddf70?mode=scale&amp;q=90&amp;h=1080&amp;w=1920" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CNN经典算法——AlexNet模型"/></a><div class="content"><a class="title" href="/2020/11/10/DL-CNN%E7%BB%8F%E5%85%B8%E8%AE%BA%E6%96%87%E2%80%94%E2%80%94AlexNet%E6%A8%A1%E5%9E%8B/" title="CNN经典算法——AlexNet模型">CNN经典算法——AlexNet模型</a><time datetime="2020-11-10T01:27:04.000Z" title="Created 2020-11-10 09:27:04">2020-11-10</time></div></div></div></div></div><div class="card-widget card-tags"><div class="card-content"><div class="item-headline"><i class="fas fa-tags"></i><span>Tags</span></div><div class="card-tag-cloud"><a href="/tags/Machine-Learning/" style="font-size: 1.4em; color: rgb(144, 120, 105)">Machine Learning</a><a href="/tags/Hexo/" style="font-size: 1.1em; color: rgb(30, 66, 155)">Hexo</a><a href="/tags/GitHub/" style="font-size: 1.1em; color: rgb(161, 18, 133)">GitHub</a><a href="/tags/Deep-Learning/" style="font-size: 1.5em; color: rgb(46, 133, 81)">Deep Learning</a><a href="/tags/Paper-Recurrence/" style="font-size: 1.3em; color: rgb(87, 143, 12)">Paper Recurrence</a><a href="/tags/CNN/" style="font-size: 1.3em; color: rgb(14, 12, 59)">CNN</a><a href="/tags/RNN/" style="font-size: 1.2em; color: rgb(99, 36, 1)">RNN</a></div></div></div><div class="card-widget card-archives"><div class="card-content"><div class="item-headline"><i class="fas fa-archive"></i><span>Archives</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/11/"><span class="card-archive-list-date">November 2020</span><span class="card-archive-list-count">7</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/10/"><span class="card-archive-list-date">October 2020</span><span class="card-archive-list-count">11</span></a></li></ul></div></div><div class="card-widget card-webinfo"><div class="card-content"><div class="item-headline"><i class="fas fa-chart-line"></i><span>Info</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">Article :</div><div class="item-count">18</div></div><div class="webinfo-item"><div class="item-name">Run time :</div><div class="item-count" id="runtimeshow" data-publishDate="2020-10-09T16:00:00.000Z"></div></div><div class="webinfo-item"><div class="item-name">Total Count :</div><div class="item-count">20.4k</div></div><div class="webinfo-item"><div class="item-name">UV :</div><div class="item-count" id="busuanzi_value_site_uv"></div></div><div class="webinfo-item"><div class="item-name">PV :</div><div class="item-count" id="busuanzi_value_site_pv"></div></div><div class="webinfo-item"><div class="item-name">Last Push :</div><div class="item-count" id="last-push-date" data-lastPushDate="2020-12-06T08:17:22.515Z"></div></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 By 侯三多</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog"></i></button><button id="chat_btn" type="button" title="rightside.chat_btn"><i class="fas fa-sms"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></section><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><div class="js-pjax"><script>function subtitleType () {
  $.getScript('https://sdk.jinrishici.com/v2/browser/jinrishici.js',function () {
    jinrishici.load(function (result) {
      if (true) {
        var sub = "From Zero to One Hundred".length == 0 ? new Array() : "From Zero to One Hundred".split(',')
        var content = result.data.content
        var both = sub.unshift(content)
        var typed = new Typed('#subtitle', {
          strings: sub,
          startDelay: 300,
          typeSpeed: 150,
          loop: true,
          backSpeed: 50,
        })
      } else {
        document.getElementById('subtitle').innerHTML = result.data.content
      }
    })
  })
}

if (true) {
  if (typeof Typed === 'function') subtitleType()
  else $.getScript('https://cdn.jsdelivr.net/npm/typed.js/lib/typed.min.js', subtitleType)
} else {
  subtitleType()
}
</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js" async="async" mobile="false"></script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-show-text.min.js" async="async" mobile="false"></script><script src="//code.tidio.co/jtw2gf0ig0ylkc0so38yv6a0syags4zs.js" async="async"></script><script>function onTidioChatApiReady() {
  window.tidioChatApi.hide();
  window.tidioChatApi.on("close", function() {
    window.tidioChatApi.hide();
  });
}
if (window.tidioChatApi) {
  window.tidioChatApi.on("ready", onTidioChatApiReady);
} else {
  document.addEventListener("tidioChat-ready", onTidioChatApiReady);
}

var chatBtnFn = () => {
  document.getElementById("chat_btn").addEventListener("click", function(){
    window.tidioChatApi.show();
    window.tidioChatApi.open();
  });
}
chatBtnFn()
</script></div></body></html>